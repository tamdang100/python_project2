{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "H48Tcvb0Ad33",
        "epS8H-FV2c_c"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Part I: EDA**\n"
      ],
      "metadata": {
        "id": "H48Tcvb0Ad33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA Task**"
      ],
      "metadata": {
        "id": "xzsXHZ9iAp7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.** Create DataFrame \"payment_enriched\" (Merge \"payment_report.csv\" with \"product.csv\")"
      ],
      "metadata": {
        "id": "1-e8eEUyPbMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Google Drive files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/DAC_K27/Module 3 - Python/Project 2/'\n",
        "\n",
        "# Import the \"pandas\" library\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files\n",
        "payment_report = pd.read_csv(path + 'payment_report.csv', encoding = 'utf-8')\n",
        "product = pd.read_csv(path + 'product.csv', encoding = 'utf-8')\n",
        "transactions = pd.read_csv(path + 'transactions.csv', encoding = 'utf-8')\n",
        "\n",
        "# Display the first few rows of each dataframe to understand their structure\n",
        "payment_report.head()\n",
        "len(payment_report) # 919\n",
        "\n",
        "product.head()\n",
        "len(product) # 492\n",
        "\n",
        "transactions.head()\n",
        "len(transactions) # 1324002"
      ],
      "metadata": {
        "id": "fdDtelQkA3tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is any duplicate in \"product_id\" column in \"product\" DataFrame as it is the primary key\n",
        "no_duplicate_id = product['product_id'].duplicated().sum()\n",
        "print(f\"Number of duplicate in product_id is: {no_duplicate_id}\") ## 0 duplicate\n"
      ],
      "metadata": {
        "id": "KXbZ3j2fNFig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the \"payment_report.csv\" with \"product.csv\" using 'product_id'\n",
        "payment_enriched = pd.merge(payment_report, product, on = 'product_id', how = 'left') # 'payment_report' has higher number of rows => left join\n",
        "\n",
        "# Display the first few rows of the resulting DataFrame\n",
        "payment_enriched.head()"
      ],
      "metadata": {
        "id": "5qlvdub2N2G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.** Explanatory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "HZdXo-13REmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2.1.*** Check each column: missing data? duplicates? incorrect data types?"
      ],
      "metadata": {
        "id": "JFxMqa5iRVaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Checking for missing data\n",
        "print(\"Missing data in 'payment_enriched':\")\n",
        "print(payment_enriched.isnull().sum()) # 'category' and 'team_own' has 22 missing values each\n",
        "\n",
        "print(\"\\nMissing data in 'transactions':\")\n",
        "print(transactions.isnull().sum()) # missing data in 'sender_id', 'receiver_id', and 'extra_info'"
      ],
      "metadata": {
        "id": "jh8-NaUNRL8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "- Missing data:\n",
        "  - DataFrame '**payment_enriched**': Column 'category' and 'team_own': 22 missing values each\n",
        "  - DataFrame '**transactions**': column 'sender_id': 49059; column\n",
        "'receiver_id': 164795; and column 'extra_info': 1317907\n",
        "\n",
        "- Next step: **No action** as removing those missing values might just lead to losing data."
      ],
      "metadata": {
        "id": "QskjUsqHfPE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Checking for duplicates\n",
        "print(\"Duplicate rows in 'payment_enriched':\")\n",
        "print(payment_enriched.duplicated().sum()) # no duplicate\n",
        "\n",
        "print(\"\\nDuplicate rows in 'transactions':\")\n",
        "print(transactions.duplicated().sum()) # 28 duplicates"
      ],
      "metadata": {
        "id": "vVXWv8RzeqXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "- Duplicate rows in '**payment_enriched**': 0\n",
        "- Duplicate rows in '**transactions**': 28\n",
        "- Next step: Remove those **28** duplicates in '**transactions**'."
      ],
      "metadata": {
        "id": "qjbbkxPrvoW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows in 'transactions'\n",
        "transactions = transactions.drop_duplicates()\n",
        "print(\"\\nDuplicate rows in 'transactions':\")\n",
        "print(transactions.duplicated().sum())"
      ],
      "metadata": {
        "id": "tYloKVN1beb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Checking data types\n",
        "print(\"Data types in payment_enriched:\")\n",
        "print(payment_enriched.dtypes)\n",
        "print(\"\\nData types in transactions:\")\n",
        "print(transactions.dtypes)"
      ],
      "metadata": {
        "id": "NHDTIccresnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "- Data type of columns in '**payment_enriched**' has 'report_month' column whose the data type should be 'datetime' instead of 'object'\n",
        "- Data type of some columns in '**transactions**' has some issues as follows.\n",
        "  - '**sender_id**' and '**receiver_id**' should be in '**int64**' instead of '**float64**'\n",
        "  - '**timeStamp**' should be in '**datetime**' instead of '**int64**'\n",
        "- Next steps:\n",
        "  - For '**payment_enriched**': Convert the datatype of '**report_month**' to '**datetime**'\n",
        "  - For '**transactions**': Convert the datatype of '**sender_id**', '**receiver_id**', and '**timeStamp**' to the correct datatypes."
      ],
      "metadata": {
        "id": "ux02grKGhUBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'report_month' to datetime format\n",
        "payment_enriched['report_month'] = pd.to_datetime(payment_enriched['report_month'], format='%Y-%m')\n",
        "\n",
        "# Convert 'sender_id' and 'receiver_id' to nullable Int64 dtype ('sender_id' and 'receiver_id' include NaN so we cannot use 'int64')\n",
        "transactions['sender_id'] = transactions['sender_id'].astype('Int64')\n",
        "transactions['receiver_id'] = transactions['receiver_id'].astype('Int64')\n",
        "\n",
        "# Convert 'timeStamp' to 'datetime'\n",
        "transactions['timeStamp'] = pd.to_datetime(transactions['timeStamp'], unit='ms')\n",
        "\n",
        "# Verify the changes\n",
        "print(payment_enriched.dtypes)\n",
        "payment_enriched.head()\n",
        "\n",
        "print(transactions.dtypes)\n",
        "transactions.head()"
      ],
      "metadata": {
        "id": "SJ26guMvg6ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2.2.*** Summarize numerical data: any incorrect values?"
      ],
      "metadata": {
        "id": "VfgI_ax6Rc-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize numerical data\n",
        "payment_enriched.describe() # All good\n",
        "\n",
        "transactions.describe() # negative values in 'transStatus', 'receiver_id'"
      ],
      "metadata": {
        "id": "XTRxd0XjRjuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of numerical columns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate histograms for all numerical columns in 'payment_enriched'\n",
        "payment_enriched.hist(figsize=(10, 8), bins=20, edgecolor='black')\n",
        "plt.suptitle('Histograms of Numerical Columns in \"payment_enriched\" DataFrame')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D1AzrCe4XTqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate histograms for all numerical columns in transactions\n",
        "transactions.hist(figsize=(10, 8), bins=20, edgecolor='black')\n",
        "plt.suptitle('Histograms of Numerical Columns in \"transactions\" DataFrame')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gzLZCfUaXOus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "- For '**payment_enriched**': numerical data looks all good\n",
        "- For '**transactions**': there are negatives values in '**transStatus**' and '**receiver_id**' => Next steps: double check with relevant department to fix incorrect ids. However, this is minor mistake."
      ],
      "metadata": {
        "id": "szgrDH2n1kN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II: Data Wrangling**"
      ],
      "metadata": {
        "id": "epS8H-FV2c_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Using '**payment_report.csv**' & '**product.csv**' (i.e., the DataFrame '**payment_enriched**'), identify top 3 product_ids with the highest volume"
      ],
      "metadata": {
        "id": "bqJjW7qn2k0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the top 3 product_ids with the highest volume\n",
        "top_3_products = payment_enriched.groupby('product_id')['volume'].sum().nlargest(3)\n",
        "\n",
        "print(\"Top 3 Product IDs with the Highest Volume:\")\n",
        "top_3_products.reset_index()"
      ],
      "metadata": {
        "id": "uSbFe6eS25fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.\tGiven that each 'product_id' is only owed by 1 team, check if there is any abnormal product that is against this rule?"
      ],
      "metadata": {
        "id": "J7Y5UTp8a-SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'product_id' and check the number of unique teams\n",
        "abnormal_products = payment_enriched.groupby('product_id')['team_own'].nunique()\n",
        "\n",
        "# Filter out product_ids with more than one unique team\n",
        "abnormal_products = abnormal_products[abnormal_products != 1]\n",
        "\n",
        "print(\"Abnormal product_ids found:\")\n",
        "abnormal_products.reset_index()['product_id']"
      ],
      "metadata": {
        "id": "NwUHWRm2blFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.\tFind the team has had the lowest performance (lowest 'volume') since Q2.2023. Find the category that contributes the least to that team."
      ],
      "metadata": {
        "id": "ScDi0BAMlYTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for Q2 2023 onward\n",
        "q2_2023_onward = payment_enriched[payment_enriched['report_month'] >= '2023-04-01']\n",
        "\n",
        "# Group by 'team_own' and sum the volume to find the lowest performing team\n",
        "team_performance = q2_2023_onward.groupby('team_own')['volume'].sum()\n",
        "lowest_team = team_performance.idxmin()\n",
        "\n",
        "print(f\"Team with the lowest performance since Q2 2023: {lowest_team}\")\n",
        "\n",
        "# Filter the data for the lowest performing team\n",
        "lowest_team_data = q2_2023_onward[q2_2023_onward['team_own'] == lowest_team]\n",
        "\n",
        "# Group by 'category' and sum the volume to find the least contributing category\n",
        "category_performance = lowest_team_data.groupby('category')['volume'].sum()\n",
        "lowest_category = category_performance.idxmin()\n",
        "\n",
        "print(f\"Category contributing the least to team {lowest_team}: {lowest_category}\")\n"
      ],
      "metadata": {
        "id": "RyRYr47lok8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.\tFind the contribution of source_ids of refund transactions (payment_group = ‘refund’), what is the source_id with the highest contribution?"
      ],
      "metadata": {
        "id": "TpnngVLmvKgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for refund transactions (payment_group = ‘refund’) only\n",
        "refund_data = payment_enriched[payment_enriched['payment_group'] == 'refund']\n",
        "\n",
        "# List the source_ids contributing to refund transactions\n",
        "refund_source_id = refund_data.groupby('source_id')['volume'].sum() # group by 'source_id' and sum the volume\n",
        "print(\"Source_ids contributing to refund transactions: \")\n",
        "refund_source_id.reset_index()['source_id']"
      ],
      "metadata": {
        "id": "N1iBKaeZvgrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the 'source_id' with the highest contribution\n",
        "highest_source_id = refund_source_id.idxmax()\n",
        "\n",
        "print(f\"The 'source_id' with the highest contribution: {highest_source_id}\")"
      ],
      "metadata": {
        "id": "WPxZGw2awZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Using 'transactions.csv', define type of transactions (‘transaction_type’) for each row, given:\n",
        "- transType = 2 & merchant_id = 1205: Bank Transfer Transaction\n",
        "- transType = 2 & merchant_id = 2260: Withdraw Money Transaction\n",
        "- transType = 2 & merchant_id = 2270: Top Up Money Transaction\n",
        "- transType = 2 & others merchant_id: Payment Transaction\n",
        "- transType = 8, merchant_id = 2250: Transfer Money Transaction\n",
        "- transType = 8 & others merchant_id: Split Bill Transaction\n",
        "- Remained cases are invalid transactions"
      ],
      "metadata": {
        "id": "hUPXaVXyySHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function (underlying conditions to categorize the transaction types)\n",
        "def defined_transaction_type(row):\n",
        "    if row['transType'] == 2 and row['merchant_id'] == 1205:\n",
        "        return 'Bank Transfer Transaction'\n",
        "    elif row['transType'] == 2 and row['merchant_id'] == 2260:\n",
        "        return 'Withdraw Money Transaction'\n",
        "    elif row['transType'] == 2 and row['merchant_id'] == 2270:\n",
        "        return 'Top Up Money Transaction'\n",
        "    elif row['transType'] == 2:\n",
        "        return 'Payment Transaction'\n",
        "    elif row['transType'] == 8 and row['merchant_id'] == 2250:\n",
        "        return 'Transfer Money Transaction'\n",
        "    elif row['transType'] == 8:\n",
        "        return 'Split Bill Transaction'\n",
        "    else:\n",
        "        return 'Invalid Transaction'\n",
        "\n",
        "# Create a new column named 'transaction_type'\n",
        "transactions['transaction_type'] = transactions.apply(defined_transaction_type, axis=1)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "transactions[['transaction_id', 'merchant_id', 'transType', 'transaction_type']].head()\n",
        "transactions\n"
      ],
      "metadata": {
        "id": "mg-lCTvT2ikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.\tOf each transaction type (excluding invalid transactions): find the number of transactions, volume, senders and receivers"
      ],
      "metadata": {
        "id": "v1uTIhYz4NE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Exclude invalid transactions\n",
        "valid_transactions = transactions[transactions['transaction_type'] != 'Invalid Transaction']\n",
        "\n",
        "# Group by 'transaction_type' and calculate the metrics\n",
        "summary = valid_transactions.groupby('transaction_type').agg(\n",
        "    no_transactions=('transaction_id', 'count'),\n",
        "    total_volume=('volume', 'sum'),\n",
        "    unique_senders=('sender_id', 'nunique'),\n",
        "    unique_receivers=('receiver_id', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Display the summary DataFrame\n",
        "summary\n"
      ],
      "metadata": {
        "id": "2f4k3rRO4pLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This is the end of Project 2 - Thank you very much for your time!** 😀"
      ],
      "metadata": {
        "id": "8KlqyWYZ5zEJ"
      }
    }
  ]
}